{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d77b0",
   "metadata": {},
   "source": [
    "#Â Bias-Variance Dilemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4941630",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e5997",
   "metadata": {},
   "source": [
    "## Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8082",
   "metadata": {},
   "source": [
    "This exercice is based on the previous exercice about overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67c364",
   "metadata": {},
   "source": [
    "Create a function `create_dataset(N)` that draws $N = 20$ points $(x_i, y_i)$, $i=1,\\dots,N$ ($x_i$'s are equidistant) according to the function:\n",
    "\n",
    "$$\n",
    "f_{\\epsilon}(x) = \\frac{1}{2}\\ +\\ \\frac{1}{100}\\exp\\left(3x\\right) + \\epsilon,~~~x \\in [-2, 2]\n",
    "$$\n",
    "\n",
    "where $\\epsilon \\sim \\mathcal{N}(\\mu=0, \\sigma=0.3)$ is some normal noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a4889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5842d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4722a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71fbd5a",
   "metadata": {},
   "source": [
    "Then create $K = 5$ different datasets \n",
    "\n",
    "$$\n",
    "\\mathcal{S}_k = \\left\\{ (x_{k,i}, y_{k,i}) : i = 1, \\dots, N \\right\\} \\text{ for } k = 1, \\dots, K\n",
    "$$\n",
    "\n",
    "and store them in a list or a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a708ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd83d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4dfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49037118",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "As in the previous exercice, we consider the **polynomial model**:\n",
    "    \n",
    "$$\n",
    "\\hat f(\\alpha; x) = \\sum_{d=0}^D \\alpha_d x^d\n",
    "$$\n",
    "\n",
    "where $\\alpha = (\\alpha_0,\\dots,\\alpha_D)$ are the parameters of the model.\n",
    "\n",
    "For instance, for $D = 3$, one has:\n",
    "$\n",
    "\\hat f(\\alpha; x) = \\alpha_0 + \\alpha_1 x + \\alpha_2 x^2 + \\alpha_3 x^3\n",
    "$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83b363",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "We alsoo consider the following **loss function** to measure the ability of a model $\\hat f(\\alpha; x)$ to fit a set of points $\\{ (x_i, y_i): i=1,\\dots,N \\}$ (sum of squared errors between the predictions and the true values):\n",
    "\\begin{align*}\n",
    "\\mathcal{L} \\left( \\alpha \\right) & = \\sum_{i=1}^N \\left( \\hat f(\\alpha; x_i)  - y_i \\right)^2 \\\\\n",
    "& = \\sum_{i=1}^N \\left( \\sum_{d=0}^D \\alpha_d x_i^d - y_i \\right)^2 \\\\\n",
    "& = \n",
    "\\left\\|~\n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "x_1^0 & \\cdots & x_1^D \\\\\n",
    "\\vdots &  & \\vdots \\\\\n",
    "x_N^0 & \\cdots & x_N^D\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "\\alpha_0 \\\\\n",
    "\\vdots \\\\\n",
    "\\alpha_D\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "-\n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "y_1 \\\\\n",
    "\\vdots \\\\\n",
    "y_N\n",
    "\\end{matrix}\n",
    "\\right)~\n",
    "\\right\\|_{2}\n",
    "\\end{align*}\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36268d18",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The **best model** is the one that minimizes the loss $\\mathcal{L} \\left( \\alpha \\right)$ on the train set\n",
    "\n",
    "$$\n",
    "\\left\\{ (x_{train_i}, y_{train_i}) : i=1,\\dots,N \\right\\}\n",
    "$$\n",
    "    \n",
    "i.e., it is the model\n",
    "\n",
    "$$\\hat f(\\alpha^*; x)$$\n",
    "where\n",
    "\\begin{align}\n",
    "\\alpha^* = (\\alpha^*_0, \\dots ,\\alpha^*_D) & = \\arg \\min_{\\alpha} \\mathcal{L} \\left( \\alpha \\right) \\\\\n",
    "& = \\arg \\min_{\\alpha}\n",
    "\\left\\|~\n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "x_{train_1}^0 & \\cdots & x_{train_1}^D \\\\\n",
    "\\vdots &  & \\vdots \\\\\n",
    "x_{train_N}^0 & \\cdots & x_{train_N}^D\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "\\alpha_0 \\\\\n",
    "\\vdots \\\\\n",
    "\\alpha_D\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "-\n",
    "\\left(\n",
    "\\begin{matrix}\n",
    "y_{train_1} \\\\\n",
    "\\vdots \\\\\n",
    "y_{train_N}\n",
    "\\end{matrix}\n",
    "\\right)~\n",
    "\\right\\|_{2}\n",
    "\\end{align}\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d62a7",
   "metadata": {},
   "source": [
    "The following function `fit(D, x_train, y_train)` returns the parameters\n",
    "\n",
    "$$\n",
    "\\alpha^* = (\\alpha^*_0, \\dots, \\alpha^*_D)\n",
    "$$\n",
    "\n",
    "of the best polynomial model $\\hat f(\\alpha^*; x)$ of degree `D` for the training set `x_train`, `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0ec34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(D, x_train, y_train):\n",
    "    \n",
    "    # compute train features (matrix X of pb (1))\n",
    "    A = x_train.unsqueeze(1).repeat(1, D+1)\n",
    "    B = torch.arange(D+1).unsqueeze(0).repeat(len(x_train), 1)\n",
    "    X_train = A ** B\n",
    "    \n",
    "    # compute best parameters alpha^* (solve pb (1))\n",
    "    alpha_star = torch.linalg.lstsq(X_train, y_train).solution\n",
    "    \n",
    "    return alpha_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd042a00",
   "metadata": {},
   "source": [
    "For each dataset $\\mathcal{S}_k$, $k = 1, \\dots, K$ and for each degree $D = 1,\\dots, 15$, compute the parameters $\\alpha^* = (\\alpha^*_0, \\dots, \\alpha^*_D)$ of the best model $\\hat f(\\alpha^*; x)$ of degree $D$ for the dataset $\\mathcal{S}_k$.\n",
    "\n",
    "Store these parameters in a list or a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d870d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8499c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9561d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f79c98fa",
   "metadata": {},
   "source": [
    "Create a procedure `plot(D, k)` which plots the best model $\\hat f(\\alpha^*; x)$ of degree $D$ for the `k`-th dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9750907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50129bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c472fb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70e30ebf",
   "metadata": {},
   "source": [
    "Plot the original function as well as the best models of degree 0 for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f76cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553b33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ab64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "961abd0b",
   "metadata": {},
   "source": [
    "Plot the original function as well as the best models of degree 1 for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69a197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089467e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c7489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75dcb803",
   "metadata": {},
   "source": [
    "Plot the original function as well as the best models of degree 5 for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b75bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bef03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a074c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af83b6bd",
   "metadata": {},
   "source": [
    "Plot the original function as well as the best models of degree 10 for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5cc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea5efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08652b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68c7ee01",
   "metadata": {},
   "source": [
    "Create a procedure `plot_2(D)` which plots the original function as well as the mean and variance of the best models $\\hat f(\\alpha^*; x)$ of degree `D` for the all the datasets.\n",
    "\n",
    "The mean model and its variance should be in the \"confidence bands\" style<br>\n",
    "https://www.mattswint.com/matplotlib-confidence-bands/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f0e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008e9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca63eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4044bdeb",
   "metadata": {},
   "source": [
    "Make the plots for the best models of degrees 0, 1, 2, 3, 5, and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9354473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd323565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a4c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c9ebf8c",
   "metadata": {},
   "source": [
    "You should notice that as **the complexity (i.e., the degree) of the model increases**:\n",
    "- **the bias of the best models decreases:**<br>\n",
    "i.e. the red curves are closer and closer to the black curve.\n",
    "- **the variance of the best models increases:**<br>\n",
    "i.e. the orange confidence bands are getting larger.\n",
    "\n",
    "This is the **bias-variance dilemma**.\n",
    "\n",
    "- The **bias** represents the error due to the model complexity.\n",
    "- The **variance** represents the sensitivity of the model to its underlying dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87868e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
