%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for CABESSA Jeremie at 2024-10-22 12:14:39 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{Werbos82,
	abstract = {The following paper summarizes the major properties and applications of a collection of algorithms involving differentiation and optimization at minimum cost. The areas of application include the sensitivity analysis of models, new work in statistical or econometric estimation, optimization, artificial intelligence and neuron modelling. The details, references and derivations can be obtained by requesting â€žSensitivity Analysis Methods for Nonlinear Systems`` from Forecast Analysis and Evaluation Team, Quality Assurance, OSS/EIA, Room 7413, Department of Energy, Washington, DC 20461.},
	address = {Berlin, Heidelberg},
	author = {Werbos, Paul J.},
	booktitle = {System Modeling and Optimization},
	date-added = {2024-10-22 12:14:23 +0200},
	date-modified = {2024-10-22 12:14:38 +0200},
	editor = {Drenick, R. F. and Kozin, F.},
	isbn = {978-3-540-39459-4},
	pages = {762--770},
	publisher = {Springer Berlin Heidelberg},
	title = {Applications of advances in nonlinear sensitivity analysis},
	year = {1982}}

@article{RumelhartEtAl86,
	abstract = {Describes back-propagation, which is a set of learning rules for
	neural networks. The procedure repeatedly adjusts the weights of
	the connections in the network so as to minimize a measure of the
	difference between the actual output vector of the net and the desired
	output vector. As a result of the weight adjustments, internal hidden
	units, not part of the input or output, come to represent important
	features of the task domain, and the regularities in the task are
	captured by the interactions of these units. The ability to create
	useful new features distinguishes back-propagation from other learning
	procedures.},
	author = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
	date-added = {2024-10-22 12:12:25 +0200},
	date-modified = {2024-10-22 12:12:45 +0200},
	journal = {Nature},
	number = {6088},
	pages = {533--536},
	title = {Learning representations by back-propagating errors.},
	volume = {323},
	year = {1986}}

@inproceedings{HeEtAl16,
	author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/cvpr/HeZRS16.bib},
	booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016},
	date-added = {2024-10-21 18:27:26 +0200},
	date-modified = {2024-10-21 18:27:49 +0200},
	doi = {10.1109/CVPR.2016.90},
	pages = {770--778},
	publisher = {{IEEE} Computer Society},
	timestamp = {Fri, 24 Mar 2023 00:02:57 +0100},
	title = {Deep Residual Learning for Image Recognition},
	url = {https://doi.org/10.1109/CVPR.2016.90},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1109/CVPR.2016.90}}

@article{LeCunEtAl98,
	author = {Yann LeCun and L{\'{e}}on Bottou and Yoshua Bengio and Patrick Haffner},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/pieee/LeCunBBH98.bib},
	date-added = {2024-10-20 12:19:53 +0200},
	date-modified = {2024-10-20 12:20:10 +0200},
	doi = {10.1109/5.726791},
	journal = {Proc. {IEEE}},
	number = {11},
	pages = {2278--2324},
	timestamp = {Wed, 16 Mar 2022 23:54:13 +0100},
	title = {Gradient-based learning applied to document recognition},
	url = {https://doi.org/10.1109/5.726791},
	volume = {86},
	year = {1998},
	bdsk-url-1 = {https://doi.org/10.1109/5.726791}}

@article{Fukushima88,
	abstract = {A neural network model for visual pattern recognition, called the ``neocognitron,'' was previously proposed by the author. In this paper, we discuss the mechanism of the model in detail. In order to demonstrate the ability of the neocognitron, we also discuss a pattern-recognition system which works with the mechanism of the neocognitron. The system has been implemented on a minicomputer and has been trained to recognize handwritten numerals. The neocognitron is a hierarchical network consisting of many layers of cells, and has variable connections between the cells in adjoining layers. It can acquire the ability to recognize patterns by learning, and can be trained to recognize any set of patterns. After finishing the process of learning, pattern recognition is performed on the basis of similarity in shape between patterns, and is not affected by deformation, nor by changes in size, nor by shifts in the position of the input patterns. In the hierarchical network of the neocognitron, local features of the input pattern are extracted by the cells of a lower stage, and they are gradually integrated into more global features. Finally, each cell of the highest stage integrates all the information of the input pattern, and responds only to one specific pattern. Thus, the response of the cells of the highest stage shows the final result of the pattern-recognition of the network. During this process of extracting and integrating features, errors in the relative position of local features are gradually tolerated. The operation of tolerating positional error a little at a time at each stage, rather than all in one step, plays an important role in endowing the network with an ability to recognize even distorted patterns.},
	author = {Kunihiko Fukushima},
	date-added = {2024-10-20 12:17:40 +0200},
	date-modified = {2024-10-20 12:17:53 +0200},
	doi = {https://doi.org/10.1016/0893-6080(88)90014-7},
	issn = {0893-6080},
	journal = {Neural Networks},
	number = {2},
	pages = {119--130},
	title = {Neocognitron: A hierarchical neural network capable of visual pattern recognition},
	url = {https://www.sciencedirect.com/science/article/pii/0893608088900147},
	volume = {1},
	year = {1988},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/0893608088900147},
	bdsk-url-2 = {https://doi.org/10.1016/0893-6080(88)90014-7}}

@article{Fukushima80,
	author = {Kunihiko Fukushima},
	date-added = {2024-10-20 12:16:32 +0200},
	date-modified = {2024-10-20 12:16:45 +0200},
	journal = {Biological Cybernetics},
	pages = {193--202},
	title = {Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
	url = {https://api.semanticscholar.org/CorpusID:206775608},
	volume = {36},
	year = {1980},
	bdsk-url-1 = {https://api.semanticscholar.org/CorpusID:206775608}}

@inproceedings{KrizhevskyEtAl12,
	author = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/nips/KrizhevskySH12.bib},
	booktitle = {Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States},
	date-added = {2024-10-20 12:10:25 +0200},
	date-modified = {2024-10-20 12:10:37 +0200},
	editor = {Peter L. Bartlett and Fernando C. N. Pereira and Christopher J. C. Burges and L{\'{e}}on Bottou and Kilian Q. Weinberger},
	pages = {1106--1114},
	timestamp = {Mon, 16 May 2022 15:41:51 +0200},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	url = {https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	year = {2012},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html}}

@inproceedings{RonnebergerEtAl15,
	author = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/miccai/RonnebergerFB15.bib},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI} 2015 - 18th International Conference Munich, Germany, October 5 - 9, 2015, Proceedings, Part {III}},
	date-added = {2024-10-20 12:08:20 +0200},
	date-modified = {2024-10-20 12:08:32 +0200},
	doi = {10.1007/978-3-319-24574-4\_28},
	editor = {Nassir Navab and Joachim Hornegger and William M. Wells III and Alejandro F. Frangi},
	pages = {234--241},
	publisher = {Springer},
	series = {Lecture Notes in Computer Science},
	timestamp = {Mon, 03 Jan 2022 22:36:27 +0100},
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {https://doi.org/10.1007/978-3-319-24574-4\_28},
	volume = {9351},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-319-24574-4%5C_28}}

@inproceedings{SimonyanZisserman15,
	author = {Karen Simonyan and Andrew Zisserman},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/SimonyanZ14a.bib},
	booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
	date-added = {2024-10-20 12:05:33 +0200},
	date-modified = {2024-10-20 12:06:18 +0200},
	editor = {Yoshua Bengio and Yann LeCun},
	timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
	title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	url = {http://arxiv.org/abs/1409.1556},
	year = {2015},
	bdsk-url-1 = {http://arxiv.org/abs/1409.1556}}

@url{OdaiboMeduim,
	author = {{Stephen Odaibo}},
	date-added = {2023-07-11 16:25:12 +0200},
	date-modified = {2023-07-11 16:26:33 +0200},
	rating = {0},
	read = {0},
	title = {Stephen Odaibo : Meduim post},
	url = {https://medium.com/retina-ai-health-inc/variational-inference-derivation-of-the-variational-autoencoder-vae-loss-function-a-true-story-3543a3dc67ee},
	year = {2020},
	bdsk-url-1 = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff}}

@url{AminiYoutube,
	author = {{Alexander Amini}},
	date-added = {2023-07-11 16:07:11 +0200},
	date-modified = {2023-07-11 16:12:58 +0200},
	rating = {0},
	read = {0},
	title = {Alexander Amini: YouTube channel},
	url = {https://www.youtube.com/@AAmini},
	year = {2022},
	bdsk-url-1 = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff}}

@url{CNRSFIDLEYoutube,
	author = {{CNRS - Formation FIDLE}},
	date-added = {2023-07-11 16:06:02 +0200},
	date-modified = {2023-07-11 16:12:26 +0200},
	rating = {0},
	read = {0},
	title = {CNRS - Formation FIDLE: YouTube channel},
	url = {https://www.youtube.com/@CNRS-FIDLE},
	year = {2022},
	bdsk-url-1 = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff}}

@url{RashkaYoutube,
	author = {{Sebastian Raschka}},
	date-added = {2023-07-11 16:04:42 +0200},
	date-modified = {2023-07-11 16:12:17 +0200},
	rating = {0},
	read = {0},
	title = {Sebastian Raschka: YouTube channel},
	url = {https://www.youtube.com/@SebastianRaschka},
	year = {2022},
	bdsk-url-1 = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff}}

@inproceedings{KingmaWelling13,
	author = {Diederik P. Kingma and Max Welling},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/KingmaW13.bib},
	booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
	date-added = {2023-07-11 16:02:45 +0200},
	date-modified = {2023-07-11 16:02:59 +0200},
	editor = {Yoshua Bengio and Yann LeCun},
	timestamp = {Thu, 04 Apr 2019 13:20:07 +0200},
	title = {Auto-Encoding Variational Bayes},
	url = {http://arxiv.org/abs/1312.6114},
	year = {2014},
	bdsk-url-1 = {http://arxiv.org/abs/1312.6114}}

@article{KingmaWelling19,
	author = {Diederik P. Kingma and Max Welling},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/ftml/KingmaW19.bib},
	date-added = {2023-07-11 16:01:00 +0200},
	date-modified = {2023-07-11 16:01:18 +0200},
	doi = {10.1561/2200000056},
	journal = {Found. Trends Mach. Learn.},
	number = {4},
	pages = {307--392},
	timestamp = {Thu, 18 Jun 2020 22:08:17 +0200},
	title = {An Introduction to Variational Autoencoders},
	url = {https://doi.org/10.1561/2200000056},
	volume = {12},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1561/2200000056}}

@misc{Alammar18,
	author = {Alammar, Jay},
	date-added = {2023-03-23 19:14:47 +0100},
	date-modified = {2023-03-23 19:15:21 +0100},
	title = {The Illustrated Transformer},
	url = {https://jalammar.github.io/illustrated-transformer/},
	year = {2018},
	bdsk-url-1 = {https://jalammar.github.io/explaining-transformers/}}

@inproceedings{VaswaniEtAl17,
	author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/nips/VaswaniSPUJGKP17.bib},
	booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}},
	date-added = {2023-03-23 18:50:27 +0100},
	date-modified = {2023-03-23 18:50:40 +0100},
	editor = {Isabelle Guyon and Ulrike von Luxburg and Samy Bengio and Hanna M. Wallach and Rob Fergus and S. V. N. Vishwanathan and Roman Garnett},
	pages = {5998--6008},
	timestamp = {Thu, 21 Jan 2021 15:15:21 +0100},
	title = {Attention is All you Need},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	year = {2017},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html}}

@webpage{CrossEntroyWiki,
	author = {{Wikipedia contributors}},
	date-added = {2022-09-26 19:29:21 +0200},
	date-modified = {2022-09-26 19:30:06 +0200},
	lastchecked = {[Online; accessed 26-September-2022]},
	rating = {0},
	read = {0},
	title = {Cross entropy --- {W}ikipedia{,} The Free Encyclopedia},
	url = {https://en.wikipedia.org/wiki/Cross_entropy},
	year = {2022},
	bdsk-url-1 = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff}}

@misc{Nielsen18,
	author = {Nielsen, Michael A.},
	date-added = {2022-08-17 11:49:53 +0200},
	date-modified = {2022-08-17 11:50:27 +0200},
	publisher = {Determination Press},
	title = {Neural Networks and Deep Learning},
	url = {http://neuralnetworksanddeeplearning.com/},
	year = 2018,
	bdsk-url-1 = {http://neuralnetworksanddeeplearning.com/}}

@book{GoodfellowEtAl16,
	author = {Ian J. Goodfellow and Yoshua Bengio and Aaron C. Courville},
	date-added = {2022-08-17 11:47:07 +0200},
	date-modified = {2022-08-17 11:47:38 +0200},
	isbn = {978-0-262-03561-3},
	publisher = {{MIT} Press},
	series = {Adaptive computation and machine learning},
	title = {Deep Learning},
	url = {http://www.deeplearningbook.org/},
	year = {2016},
	bdsk-url-1 = {http://www.deeplearningbook.org/}}

@webpage{BackpropWiki,
	author = {{Wikipedia contributors}},
	date-added = {2022-08-17 11:43:13 +0200},
	date-modified = {2022-08-17 11:43:44 +0200},
	lastchecked = {[Online; accessed 17-Augaust-2022]},
	rating = {0},
	read = {0},
	title = {Backpropagation --- {W}ikipedia{,} The Free Encyclopedia},
	url = {https://en.wikipedia.org/wiki/Backpropagation},
	year = {2022},
	bdsk-url-1 = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff}}

@webpage{GradientWiki,
	author = {{Wikipedia contributors}},
	date-added = {2022-08-14 00:52:47 +0200},
	date-modified = {2022-08-14 00:53:09 +0200},
	lastchecked = {[Online; accessed 14-Augaust-2022]},
	rating = {0},
	read = {0},
	title = {Gradient --- {W}ikipedia{,} The Free Encyclopedia},
	url = {https://fr.wikipedia.org/wiki/Gradient},
	year = {2022},
	bdsk-url-1 = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff}}

@webpage{GradientDescentWiki,
	author = {{Wikipedia contributors}},
	date-added = {2022-08-12 18:59:47 +0200},
	date-modified = {2022-08-12 19:00:26 +0200},
	lastchecked = {[Online; accessed 12-Augaust-2022]},
	rating = {0},
	read = {0},
	title = {Gradient descent --- {W}ikipedia{,} The Free Encyclopedia},
	url = {https://en.wikipedia.org/wiki/Gradient_descent},
	year = {2022},
	bdsk-url-1 = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff}}

@misc{FleuretDLC,
	author = {Fran\c{c}ois Fleuret},
	date-added = {2022-08-12 18:13:46 +0200},
	date-modified = {2022-08-12 18:17:00 +0200},
	title = {{D}eep {L}earning {C}ourse},
	url = {https://fleuret.org/dlc/},
	year = {2022},
	bdsk-url-1 = {https://fleuret.org/dlc/}}

@webpage{BiasVarianceWiki,
	author = {{Wikipedia contributors}},
	date-added = {2022-08-12 17:51:03 +0200},
	date-modified = {2022-08-12 17:58:41 +0200},
	lastchecked = {[Online; accessed 12-Augaust-2022]},
	rating = {0},
	read = {0},
	title = {Bias--variance tradeoff --- {W}ikipedia{,} The Free Encyclopedia},
	url = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff},
	year = {2022},
	bdsk-url-1 = {https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff}}

@techreport{Rosenblatt57,
	address = {Ithaca, New York},
	author = {Frank Rosenblatt},
	date-added = {2022-08-09 23:17:31 +0200},
	date-modified = {2022-08-09 23:17:31 +0200},
	institution = {Cornell Aeronautical Laboratory},
	number = {85-460-1},
	publisher = {Project PARA},
	title = {The perceptron: {A} perceiving and recognizing automaton},
	year = {1957}}

@article{Rosenblatt58,
	author = {Rosenblatt, Frank},
	date-added = {2022-08-09 23:17:31 +0200},
	date-modified = {2022-08-09 23:17:31 +0200},
	journal = {Psychological Review},
	number = {6},
	pages = {386--408},
	title = {The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain},
	volume = {65},
	year = {1958}}

@book{JamesEtAl13,
	abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform.  Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.},
	added-at = {2018-05-16T17:01:47.000+0200},
	address = {New York},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	biburl = {https://www.bibsonomy.org/bibtex/2cdaf9b657640c21d60efd38613a4df51/asalber},
	date-added = {2022-08-09 22:54:18 +0200},
	date-modified = {2022-08-12 18:17:26 +0200},
	doi = {10.1007/DOI},
	file = {SpringerLink:2013/JamesWittenEtAl2013.pdf:PDF;Springer Product page:http\://www.springer.com/978-1-4614-7137-0:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/1461471370/:URL},
	groups = {public},
	interhash = {b3febabdc45a8629023cee7323dfbd86},
	intrahash = {cdaf9b657640c21d60efd38613a4df51},
	isbn = {978-1-4614-7137-0},
	issn = {1431-875X},
	publisher = {Springer},
	series = {Springer Texts in Statistics},
	timestamp = {2018-05-16T17:01:47.000+0200},
	title = {An Introduction to Statistical Learning: with Applications in R},
	username = {flint63},
	volume = {103},
	year = 2013,
	bdsk-url-1 = {https://doi.org/10.1007/DOI}}
