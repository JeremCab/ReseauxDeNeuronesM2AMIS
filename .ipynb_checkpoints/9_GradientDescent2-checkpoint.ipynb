{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d77b0",
   "metadata": {},
   "source": [
    "#Â Gradient Descent (GD)\n",
    "# Stochastic Gradient Descent (SGD)\n",
    "# Mini-Batch Gradient Descent (mini-batch SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4941630",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e5997",
   "metadata": {},
   "source": [
    "## GD, SGD and mini-batch SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8082",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Given a dataset $S$, the \n",
    "- **Gradient Descent (GD)**\n",
    "- **Stochastic Gradient Descent (SGD)** and\n",
    "- **Mini-Batch Stochasticv Gradient Descent (mini-batch SGD)**\n",
    "    \n",
    "algorithms are given as follows:\n",
    "\n",
    "<img src=\"files/figures/GD_2.png\" width=\"650px\"/>\n",
    "    \n",
    "<img src=\"files/figures/SGD.png\" width=\"650px\"/>\n",
    "    \n",
    "<img src=\"files/figures/SGD_miniBatch.png\" width=\"650px\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8833a",
   "metadata": {},
   "source": [
    "We are going to draw a set of $N = 500$ **random points on the surface** $z = f(x, y)$ and add to them some **uniform noise**, as illustrated below.\n",
    "\n",
    "<img src=\"files/figures/surface.png\" width=\"400px\"/>\n",
    "\n",
    "More precisely:\n",
    "- Draw a set of $N = 500$ **triplets** of the form\n",
    "$$S = \\Big\\{ \\big( x_i, y_i, f(x_i, y_i) + \\epsilon \\big) : x_i, y_i \\in [-5, 5], \\epsilon \\sim \\mathcal{U} \\big( [-1,1] \\big) \\text{ and } i = 1, \\dots, N \\Big\\}$$\n",
    "where:\n",
    "    - $x_i, y_i $ are sampled uniformly inside $[-5, 5]$;\n",
    "    - $f(x_i, y_i) = \\cos(x_i) \\cdot \\cos(y_i) + \\frac{1}{10} \\cdot x_i^2 + \\frac{1}{20} \\cdot y_i^2$ is the surface equation;\n",
    "    - $\\epsilon \\sim \\mathcal{U} \\big( [-1,1] \\big)$ is a uniform noise.\n",
    "- Store these points into a numpy tensor `train_set` of size $N \\times 3$.\n",
    "- Represent these points together with the surface $z = f(x, y)$ in a 3D plot (`plt.scatter()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf7ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592702ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce686a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting the surface, fill in the surface equation on line 5\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = np.arange(-5.0, 5.0, 0.1)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = # surface equation here\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection= '3d')\n",
    "surf = ax.plot_surface(X, Y, Z, \n",
    "                       cmap='YlOrRd', \n",
    "                       linewidth=0, \n",
    "                       antialiased='True', \n",
    "                       rstride=3, \n",
    "                       cstride=3, \n",
    "                       alpha=0.5\n",
    "                      )\n",
    "\n",
    "# points\n",
    "points = ax.scatter(train_set[:, 0], train_set[:, 1], train_set[:, 2],\n",
    "                    color = 'black',\n",
    "                    marker=\"o\"\n",
    "                   )\n",
    "\n",
    "ax.set_xlim([-5.0, 5.0])\n",
    "ax.set_ylim([-5.0, 5.0])\n",
    "ax.set_zlim([-1.0, 5.0])\n",
    "# plt.title(\"Surface Plot\", size=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d1abf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Consider the **quadratic model** given by\n",
    "\n",
    "$$\n",
    "\\hat f \\left( x, y; \\Theta \\right) = \\omega_0 x^4 + \\omega_1 x^3y + \\omega_2 x^2y^2 + \\omega_3 x y^3 + \\omega_4 y^4 + \\omega_5\n",
    "$$\n",
    "\n",
    "where $\\Theta = (w_0, w_1, w_2, w_3, w_4, w_5)$ are the **parameters** of the model. Obviously, different parameters $\\Theta$ give rise to different models $\\hat f(\\cdot, \\cdot; \\boldsymbol{\\Theta})$.\n",
    "\n",
    "<br>    \n",
    "    \n",
    "Let $\\hat f(\\cdot, \\cdot; \\Theta)$ be a **model**, $B = \\big\\{ (x_i, y_i, z_i) : i = 1, \\dots, K \\big\\}$ be a **batch of points** and $p_i = (x_i, y_i, z_i) \\in B$ be a **point**:\n",
    "- The **prediction** for $(x_i, y_i)$ by $\\hat f$ is $\\hat f(x_i, y_i; \\Theta)$.\n",
    "- The **(real) target** of $(x_i, y_i)$ is $z_i= \\cos(x_i) \\cdot \\cos(y_i) + \\frac{1}{10} \\cdot x_i^2 + \\frac{1}{20} \\cdot y_i^2$.\n",
    "- The **individual loss** for $p_i$ is the distance between the target and the prediction\n",
    "    \n",
    "$$\n",
    "\\ell \\left( z_i , \\hat f(x_i, y_i; \\Theta) \\right) = \\frac{1}{2} \\left( z_i - \\hat f(x_i, y_i; \\Theta) \\right)^2.\n",
    "$$\n",
    "    \n",
    "- The **collective loss** for $B$ is the distance between all targets and predictions\n",
    "    \n",
    "$$\n",
    "\\mathcal{L} \\left( z_1, \\dots, z_K , \\hat f(x_1, y_1; \\Theta), \\dots, \\hat f(x_N, y_K; \\Theta) \\right) = \\frac{1}{2K} \\sum_{i=1}^K \\left( z_i - \\hat f(x_i, y_i; \\Theta) \\right)^2.\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd574f3",
   "metadata": {},
   "source": [
    "- Write a function<br>\n",
    "`hat_f(x, y, theta)`<br>\n",
    "that implements the **model** $\\hat f(x, y; \\Theta)$.\n",
    "- Write a function<br> \n",
    "`small_loss(x_i, y_i, z_i, theta)`<br>\n",
    "that implements the **individual loss** $\\ell \\left( z_i , \\hat f(x_i, y_i; \\Theta) \\right)$, where `x_i`,`y_i` and `z_i` are values.\n",
    "- Write a function<br>\n",
    "`big_loss(x_t, y_t, z_t, theta)`<br>\n",
    "that implements the **collective loss** $\\mathcal{L} \\left( z_1, \\dots, z_K , \\hat f(x_1, y_1; \\Theta), \\dots, \\hat f(x_N, y_K; \\Theta) \\right)$, where `x_t`,`y_t` and `z_t` are tensors of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd4514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d5bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f46bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f66345c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "We have\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla \\ell(x_i, y_i, z_i; \\Theta) & =\n",
    "\\frac{\\partial \\left[ \\frac{1}{2} \\left( z_i - \\hat f(x_i, y_i; \\Theta) \\right)^2 \\right]}{\\partial \\Theta} \\\\\n",
    "& =\n",
    "- \\left( z_i - \\hat f(x_i, y_i; \\Theta) \\right) \\cdot \\frac{\\partial \\hat f(x_i, y_i; \\Theta)}{\\partial \\Theta}\n",
    "\\end{align}\n",
    "\n",
    "and \n",
    "\n",
    "\\begin{align}\n",
    "\\nabla \\mathcal{L}(x_i, y_i, z_i; \\Theta) & =\n",
    "\\frac{\\partial \\left[ \\frac{1}{2K} \\sum_{i=1}^K \\left( z_i - \\hat f(x_i, y_i; \\Theta) \\right)^2 \\right]}{\\partial \\Theta} \\\\\n",
    "& =\n",
    "- \\frac{1}{K} \\sum_{i=1}^K \\left( z_i - \\hat f(x_i, y_i; \\Theta) \\right) \\cdot \\frac{\\partial \\hat f(x_i, y_i; \\Theta)}{\\partial \\Theta}\n",
    "\\end{align}\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739afc1e",
   "metadata": {},
   "source": [
    "- Write a function<br>\n",
    "`grad_small_loss(x_i, y_i, z_i, theta)`<br>\n",
    "that implements the **gradient of the individual loss** $\\nabla \\ell(x_i, y_i, z_i; \\Theta)$\n",
    "- Write a function<br>\n",
    "`grad_big_loss(x_t, y_t, z_t, theta)`<br>\n",
    "that implements the **gradient of the collective loss** $\\nabla \\mathcal{L}(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}; \\Theta)$ as the sum of the gradients of the individual losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eda14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696abe72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f5edba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53257866",
   "metadata": {},
   "source": [
    "Using your functions `grad_small_loss(...)` and `grad_big_loss(...)`, write the three following functions:\n",
    "\n",
    "- `GD(dataset, lamda, nb_epochs)`<br>\n",
    "    \n",
    "    that implements the **gradient descent (GD)** algorithm.<br>\n",
    "    Run this function with the parameters: `dataset=train_set`, `lamda=1e-5`, `nb_epochs=1000`.<br>\n",
    "    Check the collective loss with the parameters `theta` that you obtain.<br><br>\n",
    "\n",
    "- `SGD(dataset, lamda, nb_epochs)`<br>\n",
    "    \n",
    "    that implements the **stochastic gradient descent (SGD)** algorithm.<br>\n",
    "    Run this function with the parameters: `dataset=train_set`, `lamda=1e-8`, `nb_epochs=1000`.<br>\n",
    "    Check the collective loss with the parameters `theta` that you obtain.<br><br>\n",
    "    \n",
    "- `mini_SGD(dataset, batch_size, lamda, nb_epochs)`<br>\n",
    "    \n",
    "    that implements the **mini-batch stochastic gradient descent (mini-batch SGD)** algorithm.<br>\n",
    "    Run this function with the parameters: `dataset=train_set`, `lamda=1e-8`, `nb_epochs=1000`, `batch_size=64`.\n",
    "    Check the collective loss with the parameters `theta` that you obtain.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03fc07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119468c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7998e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13a2a13f",
   "metadata": {},
   "source": [
    "- Plot your **best model** $\\hat f(\\cdot, \\cdot; \\Theta)$ together with your **train set** by replacing the `your_parameters_theta`by the best parameters that you obtained in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = np.arange(-5.0, 5.0, 0.1)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "# Z = hat_f(X, Y, your_parameters_theta)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection= '3d')\n",
    "surf = ax.plot_surface(X, Y, Z, \n",
    "                       cmap='YlOrRd', \n",
    "                       linewidth=0, \n",
    "                       antialiased='True', \n",
    "                       rstride=3, \n",
    "                       cstride=3, \n",
    "                       alpha=0.5\n",
    "                      )\n",
    "\n",
    "# points\n",
    "points = ax.scatter(train_set[:, 0], train_set[:, 1], train_set[:, 2],\n",
    "                    color = 'black',\n",
    "                    marker=\"o\"\n",
    "                   )\n",
    "\n",
    "ax.set_xlim([-5.0, 5.0])\n",
    "ax.set_ylim([-5.0, 5.0])\n",
    "ax.set_zlim([-1.0, 5.0])\n",
    "plt.title(\"Surface Plot\", size=14)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
