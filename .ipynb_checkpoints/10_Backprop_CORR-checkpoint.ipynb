{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d77b0",
   "metadata": {},
   "source": [
    "# Backpropagation (BP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4941630",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e5997",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8082",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "The **backpropagation algorithm (BP)** is an efficient implementation of (mini-batch) stochastic gradient descent for neural networks.\n",
    "    \n",
    "In short, the algorithm consists of:\n",
    "1. a **forward pass**: computation of the activations;\n",
    "2. a **backward pass**: computation of the gradients;\n",
    "3. an **updating step**: updating of the weights and biases using gradients.\n",
    "\n",
    "<img src=\"figures/backprop.png\" width=\"800px\"/>\n",
    "    \n",
    "We will use the following **sigmoid activation function**\n",
    "    $$\n",
    "    \\sigma(z) = \\frac{1}{1 + \\exp(-z)}\n",
    "    $$\n",
    "whose derivative is given by\n",
    "    $$\n",
    "    \\sigma'(z) = \\sigma(z) \\cdot \\left( 1 - \\sigma(z) \\right).\n",
    "    $$\n",
    "\n",
    "Furthermore, we will use the following **quadratic loss function**\n",
    "    $$\n",
    "    \\mathcal{L_k} \\left( \\Theta \\right) := \\mathcal{L_k} \\left( \\Theta, \\boldsymbol{a_k^{[L]}}, \\boldsymbol{y_k} \\right) = \\frac{1}{2} \\left\\| \\boldsymbol{a_k^{[L]}} - \\boldsymbol{y_k} \\right\\|^{2}\n",
    "    $$\n",
    "whose gradient with respect to $\\boldsymbol{a_k^{[L]}}$ is given by\n",
    "    $$\n",
    "    \\nabla_{\\boldsymbol{a_k^{[L]}}} \\mathcal{L_k} \\left( \\Theta \\right) = \\boldsymbol{a_k^{[L]}} - \\boldsymbol{y_k}.\n",
    "    $$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48445972",
   "metadata": {},
   "source": [
    "**Step 1**\n",
    "- Implement the activation functions ``sigma(z)`` and its derivative ``sigma_prime(z)``.\n",
    "- Implement the loss function ``loss(a_k, y_k)`` and gradient ``loss_gradient(a_k, y_k)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1bc8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function\"\"\"\n",
    "    return 1.0 / (1.0 + torch.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275bb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6155d6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5872, 0.7295, 0.6800, 0.6185],\n",
       "        [0.5353, 0.5750, 0.6754, 0.5974],\n",
       "        [0.6966, 0.6936, 0.7082, 0.6467]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e170d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2424, 0.1973, 0.2176, 0.2360],\n",
       "        [0.2488, 0.2444, 0.2192, 0.2405],\n",
       "        [0.2114, 0.2125, 0.2066, 0.2285]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_prime(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e15485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(a_k, y_k):\n",
    "    \"\"\"Loss function\"\"\"\n",
    "    return 1/2 * torch.norm(torch.square(a_k - y_k), dim=0) # dim=0 enables batch parallelization\n",
    "\n",
    "def loss_gradient(a_k, y_k):\n",
    "    \"\"\"Gradient of the loss w.r.t a^L_k\"\"\"\n",
    "    return a_k - y_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e943a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_k = torch.rand(10)\n",
    "y_k = torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee114e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6222)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(a_k, y_k) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ddc53f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6781,  0.7698, -0.3296, -0.8301, -0.0537,  0.0857, -0.2895,  0.7413,\n",
       "        -0.1979,  0.6593])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_gradient(a_k, y_k) # vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03370880",
   "metadata": {},
   "source": [
    "**Step 2**\n",
    "- Create a class `Network()` which takes a list `[n0, n2, ..., nL]` as parameter and creates an MLP with $L+1$ layers of $n_i$ neurons each, for $i= 0, \\dots, L$.\n",
    "- Initializes the weights matrices $\\boldsymbol{W^{[l]}}$ and the bias vectors $\\boldsymbol{b^{[l]}}$ randomly from a normal distribution $\\mathcal{N}(0, 1)$ (`torch.normal()`), for $l = 0, \\dots, L-1$.<br>\n",
    "(Note that according to our notation, for $L+1$ layers, there are $L$ weights and $L$ biases.)\n",
    "- The first layer is the input layer and thus has no biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe1490",
   "metadata": {},
   "source": [
    "**Step 3**\n",
    "- Implement a method ``forward_pass(self, X)`` which:\n",
    "    - takes as inputs a batch of data $\\boldsymbol{X}$ (2D tensor)\n",
    "    - returns as outputs:\n",
    "        - the list of pre-activations ``Z_l`` = $\\left[ \\boldsymbol{Z}^{[0]}, \\boldsymbol{Z}^{[1]}, \\dots, \\boldsymbol{Z}^{[L]} \\right]$ associated to $\\boldsymbol{X}$ (list of 2D tensors).\n",
    "        - the list of activations ``A_l`` = $\\left[ \\boldsymbol{A}^{[0]}, \\boldsymbol{A}^{[1]}, \\dots, \\boldsymbol{A}^{[L]} \\right]$ associated to $\\boldsymbol{X}$ (list of 2D tensors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e518fb2",
   "metadata": {},
   "source": [
    "**Step 4**\n",
    "- Implement a method ``backward_pass(self, Z_l, A_l, Y, eta)`` which:\n",
    "    - takes as inputs:\n",
    "        - the list of pre-activations ``Z_l`` = $\\left[ \\boldsymbol{Z}^{[0]}, \\boldsymbol{Z}^{[1]}, \\dots, \\boldsymbol{Z}^{[L]} \\right]$ (list of 2D tensors).\n",
    "        - the list of activations ``A_l`` = $\\left[ \\boldsymbol{A}^{[0]}, \\boldsymbol{A}^{[1]}, \\dots, \\boldsymbol{A}^{[L]} \\right]$ (list of 2D tensors).\n",
    "        - the batch of targets ``Y`` (2D tensor);\n",
    "        - the learning rate ``eta`` (float).\n",
    "    - updates the attributes ``self.weights`` and ``self.biases`` according to the backward pass.\n",
    "    \n",
    "**Remark:** note that ``Z_l`` and ``A_l`` contain one more element that ``self.weights``. Accordingly, indices might get confusing. The following picture clarifies the situation:<br>\n",
    "```\n",
    "In algo: z^[0]                z^[1]                z^[2]                 ...\n",
    "In code: Z_l[0]               Z_l[1]               Z_l[2]                ...\n",
    "In algo: a^[0]                a^[1]                a^[2]                 ...\n",
    "In code: A_l[0]               A_l[1]               A_l[2]                ...\n",
    "In algo:            W^[1]                W^[2]                W^[3]      ...\n",
    "In code:       self.weights[0]      self.weights[1]      self.weights[2] ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef4acbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        \n",
    "        # for W and b, there are len(sizes) - 1 layers\n",
    "        self.num_layers = len(sizes) - 1\n",
    "        self.sizes = sizes\n",
    "        self.biases = [torch.normal(0, 1, size=(n, 1)) \n",
    "                       for n in sizes[1:]]\n",
    "        self.weights = [torch.normal(0, 1, size=(n2, n1)) \n",
    "                        for n1, n2 in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def forward_pass(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch.Tensor\n",
    "            batch of inputs : each column is an input (imput_dim x batch_size)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Z_l, A_l : tuple\n",
    "            Z_l : list of pre-activations Z_l's (2D tensors)\n",
    "            A_l : list of activations A_l's (2D tensors)\n",
    "        \"\"\"\n",
    "        \n",
    "        Z_l = [X]\n",
    "        A_l = [X]\n",
    "        \n",
    "        if X.shape[0] != self.sizes[0]:\n",
    "            raise ValueError(\"incorrect input dimension\")\n",
    "            \n",
    "        A = X\n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            Z = torch.mm(W, A) + b\n",
    "            A = sigmoid(Z)\n",
    "            Z_l.append(Z)\n",
    "            A_l.append(A)\n",
    "            \n",
    "        return Z_l, A_l\n",
    "    \n",
    "    \n",
    "    def backward_pass(self, Z_l, A_l, Y, eta=0.1):\n",
    "        \"\"\"\n",
    "        Backward pass\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        weights, biases, Z_l, A_l, Y : tuple\n",
    "            Z_l : list of pre-activations Z_l's (list of 2D tensors)\n",
    "            A_l : list of activations A_l's (list of 2D tensors)\n",
    "            Y : batch of targets, where each column is an target (imput_dim x batch_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        delta_last = None\n",
    "        \n",
    "        # Remark: layers are numbered from 0 to self.num_layers-1 (included)\n",
    "        for l in range(self.num_layers-1, -1, -1):\n",
    "            \n",
    "            if l == self.num_layers-1:\n",
    "                # Remark: A_l[l+1] is $a^[l]$ and Z_l[l+1] is $z^[l]$!\n",
    "                delta = loss_gradient(A_l[l+1], Y) * sigmoid_prime(Z_l[l+1])\n",
    "                delta_last = delta.clone() # update last error\n",
    "            else:\n",
    "                # Remark: self.weights[l+1] is $W^[l+1]$ but Z_l[l+1] is $z^[l]$\n",
    "                delta = torch.mm(self.weights[l+1].T, delta_last) * sigmoid_prime(Z_l[l+1])\n",
    "                delta_last = delta.clone() # update last error\n",
    "            \n",
    "            # compute gradients\n",
    "            # before mean, grad_W is a 3D tensors (batch_size x n2 x n1)\n",
    "            # before mean, grad_b is a 2D tensors (n2 x batch_size)\n",
    "            delta_batched = delta.unsqueeze(dim=0).transpose(0, 2)\n",
    "            A_l_batched_T = A_l[l].unsqueeze(dim=0).transpose(0, 2).transpose(1, 2)\n",
    "            grad_W = torch.bmm(delta_batched, A_l_batched_T)\n",
    "            grad_W = torch.mean(grad_W, 0)              # mean along batch dim\n",
    "            grad_b = delta\n",
    "            grad_b = torch.mean(delta, 1, keepdim=True) # mean along batch dim + keep dim to save extra dim\n",
    "            \n",
    "            # update gradients\n",
    "            self.weights[l] = self.weights[l] - eta*grad_W\n",
    "            self.biases[l] = self.biases[l] - eta*grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217fabcd",
   "metadata": {},
   "source": [
    "**Step 5**\n",
    "- Using your class ``Network``, initialize a network as follows:<br>\n",
    "    ``net = Network([100, 200, 300, 150, 5])``\n",
    "- Implement a forward pass on a random tensor ``X`` of size $100 \\times 32$.\n",
    "- Implement a backward pass using a random tensor ``Y`` of size $5 \\times 32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f097dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net = Network([100, 200, 300, 150, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88458f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight dim:\t torch.Size([200, 100])\n",
      "bias dim:\t torch.Size([200, 1]) \n",
      "\n",
      "weight dim:\t torch.Size([300, 200])\n",
      "bias dim:\t torch.Size([300, 1]) \n",
      "\n",
      "weight dim:\t torch.Size([150, 300])\n",
      "bias dim:\t torch.Size([150, 1]) \n",
      "\n",
      "weight dim:\t torch.Size([5, 150])\n",
      "bias dim:\t torch.Size([5, 1]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for W, b in zip(net.weights, net.biases):\n",
    "    print(\"weight dim:\\t\", W.shape)\n",
    "    print(\"bias dim:\\t\", b.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20057a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 1\n",
      "\tDim of Z^l: torch.Size([100, 32])\n",
      "\tDim of A^l: torch.Size([100, 32])\n",
      "Layer: 2\n",
      "\tDim of Z^l: torch.Size([200, 32])\n",
      "\tDim of A^l: torch.Size([200, 32])\n",
      "Layer: 3\n",
      "\tDim of Z^l: torch.Size([300, 32])\n",
      "\tDim of A^l: torch.Size([300, 32])\n",
      "Layer: 4\n",
      "\tDim of Z^l: torch.Size([150, 32])\n",
      "\tDim of A^l: torch.Size([150, 32])\n",
      "Layer: 5\n",
      "\tDim of Z^l: torch.Size([5, 32])\n",
      "\tDim of A^l: torch.Size([5, 32])\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "X = torch.rand(100, 32)\n",
    "Y = torch.rand(5, 32)\n",
    "\n",
    "Z_l, A_l = net.forward_pass(X)\n",
    "\n",
    "layer = 1\n",
    "for Z, A in zip(Z_l, A_l):\n",
    "    print(\"Layer:\", layer)\n",
    "    print(\"\\tDim of Z^l:\", Z.shape)\n",
    "    print(\"\\tDim of A^l:\", A.shape)\n",
    "    layer += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05655397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses:\t\t torch.Size([32])\n",
      "loss gradients:\t torch.Size([5, 32])\n"
     ]
    }
   ],
   "source": [
    "# losses\n",
    "losses = loss(A_l[-1], Y)\n",
    "print(\"losses:\\t\\t\", losses.shape)\n",
    "\n",
    "loss_gradients = loss_gradient(A_l[-1], Y)\n",
    "print(\"loss gradients:\\t\", loss_gradients.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "887e26aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight dim:\t torch.Size([200, 100]) torch.Size([200, 100]) tensor(True)\n",
      "bias dim:\t torch.Size([200, 1]) torch.Size([200, 1]) tensor(True) \n",
      "\n",
      "weight dim:\t torch.Size([300, 200]) torch.Size([300, 200]) tensor(True)\n",
      "bias dim:\t torch.Size([300, 1]) torch.Size([300, 1]) tensor(True) \n",
      "\n",
      "weight dim:\t torch.Size([150, 300]) torch.Size([150, 300]) tensor(True)\n",
      "bias dim:\t torch.Size([150, 1]) torch.Size([150, 1]) tensor(True) \n",
      "\n",
      "weight dim:\t torch.Size([5, 150]) torch.Size([5, 150]) tensor(True)\n",
      "bias dim:\t torch.Size([5, 1]) torch.Size([5, 1]) tensor(True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# copy weights and biases\n",
    "weights = [x.detach().clone() for x in net.weights]\n",
    "biases = [x.detach().clone() for x in net.biases]\n",
    "\n",
    "for W1, W2, b1, b2 in zip(net.weights, weights, net.biases, biases):\n",
    "    print(\"weight dim:\\t\", W1.shape, W2.shape, (W1==W2).all())\n",
    "    print(\"bias dim:\\t\", b1.shape, b2.shape, (b1==b2).all(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7197809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "net.backward_pass(Z_l, A_l, Y, eta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94e6802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight dim:\t torch.Size([200, 100]) torch.Size([200, 100]) tensor(False)\n",
      "bias dim:\t torch.Size([200, 1]) torch.Size([200, 1]) tensor(False) \n",
      "\n",
      "weight dim:\t torch.Size([300, 200]) torch.Size([300, 200]) tensor(False)\n",
      "bias dim:\t torch.Size([300, 1]) torch.Size([300, 1]) tensor(False) \n",
      "\n",
      "weight dim:\t torch.Size([150, 300]) torch.Size([150, 300]) tensor(False)\n",
      "bias dim:\t torch.Size([150, 1]) torch.Size([150, 1]) tensor(False) \n",
      "\n",
      "weight dim:\t torch.Size([5, 150]) torch.Size([5, 150]) tensor(False)\n",
      "bias dim:\t torch.Size([5, 1]) torch.Size([5, 1]) tensor(False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for W1, W2, b1, b2 in zip(net.weights, weights, net.biases, biases):\n",
    "    print(\"weight dim:\\t\", W1.shape, W2.shape, (W1==W2).all())\n",
    "    print(\"bias dim:\\t\", b1.shape, b2.shape, (b1==b2).all(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edac4cd",
   "metadata": {},
   "source": [
    "# Application to the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293f4a4",
   "metadata": {},
   "source": [
    "The **MNIST dataset** consists of handwritten digits. The MNIST classification problem consists in predicting the correct digit represented on an image.\n",
    "\n",
    "<img src=\"files/figures/mnist.png\" width=\"600px\"/>\n",
    "\n",
    "- Load the train and test MNIST datasets using the following commands:\n",
    "```\n",
    "train = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "```\n",
    "Each sample consists of a tensor (the image encoded in black and white), and a label (the digit that it represents).\n",
    "- Examine the train and test sets.\n",
    "- Visualize some data samples (tensors) using `plt.imshow()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1950affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1ec6f6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5b9e2",
   "metadata": {},
   "source": [
    "A **dataloader** creates batches of samples from a dataset so that they can be passed into a model.\n",
    "- Create a train and test dataloaders using the following commands:\n",
    "```\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)\n",
    "```\n",
    "- Note that dataloaders are not subscriptable.\n",
    "- Try to catch one batch of the dataloader and examine it.\n",
    "- Write a function that reshapes a batch of size $32 \\times 1 \\times 28 \\times 28$ into a tensor of size $784 \\times 32$.<br>\n",
    "(use `torch.squeeze()`, `torch.reshape()`, `torch.flatten()`, `torch.transpose()`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1a49538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32ea03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ea62b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_batch(b):\n",
    "    \"\"\"reshape batch of tensors\"\"\"\n",
    "    b = torch.squeeze(b)\n",
    "    b = torch.flatten(b, 1, 2).T\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31a13eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 32])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_reshaped = reshape_batch(b[0])\n",
    "b_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f651fe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 32])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(b[1] % 10).T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bbb26e",
   "metadata": {},
   "source": [
    "Instantiate a 4-layer MLP with the following characteristics:\n",
    "- Layer 1 (or input layer): size 784\n",
    "- Layer 2: size 128\n",
    "- Layer 3: size 128\n",
    "- Layer 4 (or output layer): size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0d5719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Network([784, 128, 128, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a679d",
   "metadata": {},
   "source": [
    "- Train your network for 40 epochs with a learning rate of $0.1$.\n",
    "- Write a ``train()``function that uses your methods ``forward_pass()`` and ``backward_pass()``.\n",
    "- Compute and store the loss after each batch processing:<br>\n",
    "    You can one-hot encode the targets and use your function ``loss()``.<br>\n",
    "    https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html\n",
    "- Print the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e7df52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, network, nb_epochs=1, lr=0.1):\n",
    "    \"\"\"\n",
    "    Train a network on a dataloader \n",
    "    during a certain number of epochs \n",
    "    and with a certain learning rate.\n",
    "    \"\"\"\n",
    "\n",
    "    loss_l = []\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        \n",
    "        for i, b in enumerate(dataloader):\n",
    "            \n",
    "            # print a dot every 10 batches\n",
    "            if i % 100 == 0:\n",
    "                print(\".\", end='')\n",
    "\n",
    "            # samples and targets\n",
    "            samples = reshape_batch(b[0])                     # dim [784 x 32]\n",
    "            targets = F.one_hot(b[1] % 10, num_classes=10).T  # dim [10 x 32]\n",
    "\n",
    "            # forward pass\n",
    "            Z_l, A_l = network.forward_pass(samples)\n",
    "            \n",
    "            # compute batch loss\n",
    "            if i % 50 == 0:\n",
    "                current_loss = loss(A_l[-1], targets).mean()\n",
    "                loss_l.append(current_loss)\n",
    "            \n",
    "            # backward pass\n",
    "            network.backward_pass(Z_l, A_l, targets, eta=lr)\n",
    "            \n",
    "        print(f\" \\nEpoch {e+1} completed\")\n",
    "    \n",
    "    return network, loss_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a5234f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................... \n",
      "Epoch 1 completed\n",
      "................... \n",
      "Epoch 2 completed\n",
      "................... \n",
      "Epoch 3 completed\n",
      "................... \n",
      "Epoch 4 completed\n",
      "................... \n",
      "Epoch 5 completed\n",
      "................... \n",
      "Epoch 6 completed\n",
      "................... \n",
      "Epoch 7 completed\n",
      "................... \n",
      "Epoch 8 completed\n",
      "................... \n",
      "Epoch 9 completed\n",
      "................... \n",
      "Epoch 10 completed\n",
      "................... \n",
      "Epoch 11 completed\n",
      "................... \n",
      "Epoch 12 completed\n",
      "................... \n",
      "Epoch 13 completed\n",
      "................... \n",
      "Epoch 14 completed\n",
      "................... \n",
      "Epoch 15 completed\n",
      "................... \n",
      "Epoch 16 completed\n",
      "................... \n",
      "Epoch 17 completed\n",
      "................... \n",
      "Epoch 18 completed\n",
      "................... \n",
      "Epoch 19 completed\n",
      "................... \n",
      "Epoch 20 completed\n",
      "................... \n",
      "Epoch 21 completed\n",
      "................... \n",
      "Epoch 22 completed\n",
      "................... \n",
      "Epoch 23 completed\n",
      "................... \n",
      "Epoch 24 completed\n",
      "................... \n",
      "Epoch 25 completed\n",
      "................... \n",
      "Epoch 26 completed\n",
      "................... \n",
      "Epoch 27 completed\n",
      "................... \n",
      "Epoch 28 completed\n",
      "................... \n",
      "Epoch 29 completed\n",
      "................... \n",
      "Epoch 30 completed\n",
      "................... \n",
      "Epoch 31 completed\n",
      "................... \n",
      "Epoch 32 completed\n",
      "................... \n",
      "Epoch 33 completed\n",
      "................... \n",
      "Epoch 34 completed\n",
      "................... \n",
      "Epoch 35 completed\n",
      "................... \n",
      "Epoch 36 completed\n",
      "................... \n",
      "Epoch 37 completed\n",
      "................... \n",
      "Epoch 38 completed\n",
      "................... \n",
      "Epoch 39 completed\n",
      "................... \n",
      "Epoch 40 completed\n",
      "................... \n",
      "Epoch 41 completed\n",
      "................... \n",
      "Epoch 42 completed\n",
      "................... \n",
      "Epoch 43 completed\n",
      "................... \n",
      "Epoch 44 completed\n",
      "................... \n",
      "Epoch 45 completed\n",
      "................... \n",
      "Epoch 46 completed\n",
      "................... \n",
      "Epoch 47 completed\n",
      "................... \n",
      "Epoch 48 completed\n",
      "................... \n",
      "Epoch 49 completed\n",
      "................... \n",
      "Epoch 50 completed\n"
     ]
    }
   ],
   "source": [
    "mlp, train_loss = train(train_loader, mlp, nb_epochs=50, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf657e4",
   "metadata": {},
   "source": [
    "- Write a function ``predict(network, dataloader)`` that returns the targets and predictions of a dataset.\n",
    "- Compute the classification reports for the train and test sets:<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a15aa350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff0b4ee1760>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.plot(range(len(train_loss)), train_loss, linewidth=2.0, label='training loss')\n",
    "plt.xlabel(\"Steps (epochs)\", size=12)\n",
    "plt.ylabel(\"Loss\", size=12)\n",
    "plt.savefig(\"figures/loss.pdf\", bbox_inches='tight')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b1166a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, dataloader):\n",
    "    \"\"\"Compute network predictions for a dataloader\"\"\"\n",
    "    \n",
    "    preds_l = []\n",
    "    targets_l = []\n",
    "    \n",
    "    for i, b in enumerate(dataloader):\n",
    "        \n",
    "        # print a dot every 10 batches\n",
    "        if i % 100 == 0:\n",
    "            print(\".\", end='')\n",
    "\n",
    "        # samples and targets\n",
    "        samples = reshape_batch(b[0])\n",
    "        targets = b[1].tolist()\n",
    "        targets_l.extend(targets)\n",
    "\n",
    "        # forward pass\n",
    "        Z_l, A_l = network.forward_pass(samples)\n",
    "        \n",
    "        # predictions\n",
    "        preds = torch.argmax(A_l[-1], dim=0).tolist()\n",
    "        preds_l.extend(preds)\n",
    "    \n",
    "    print(\"\\nProcessing finished\")\n",
    "    \n",
    "    return preds_l, targets_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0502f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................\n",
      "Processing finished\n"
     ]
    }
   ],
   "source": [
    "train_preds_l, train_targets_l = predict(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "709bef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      5923\n",
      "           1       0.97      0.97      0.97      6742\n",
      "           2       0.92      0.92      0.92      5958\n",
      "           3       0.91      0.89      0.90      6131\n",
      "           4       0.93      0.95      0.94      5842\n",
      "           5       0.90      0.89      0.89      5421\n",
      "           6       0.95      0.96      0.96      5918\n",
      "           7       0.94      0.95      0.94      6265\n",
      "           8       0.89      0.89      0.89      5851\n",
      "           9       0.93      0.90      0.91      5949\n",
      "\n",
      "    accuracy                           0.93     60000\n",
      "   macro avg       0.93      0.93      0.93     60000\n",
      "weighted avg       0.93      0.93      0.93     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train results\\n\")\n",
    "print(classification_report(train_targets_l, train_preds_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58b609be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "Processing finished\n"
     ]
    }
   ],
   "source": [
    "test_preds_l, test_targets_l = predict(mlp, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10081b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.92      0.89      0.90      1032\n",
      "           3       0.90      0.89      0.90      1010\n",
      "           4       0.92      0.93      0.92       982\n",
      "           5       0.87      0.89      0.88       892\n",
      "           6       0.93      0.93      0.93       958\n",
      "           7       0.93      0.93      0.93      1028\n",
      "           8       0.89      0.90      0.89       974\n",
      "           9       0.92      0.89      0.91      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test results\\n\")\n",
    "print(classification_report(test_targets_l, test_preds_l))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
