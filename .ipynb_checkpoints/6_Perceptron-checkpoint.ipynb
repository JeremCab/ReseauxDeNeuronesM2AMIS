{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d77b0",
   "metadata": {},
   "source": [
    "#Â The Percepron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4941630",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e5997",
   "metadata": {},
   "source": [
    "## Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8082",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The **perceptron** is a single neuron (as illustrated below) which acts as a binary classifier.\n",
    "\n",
    "<img src=\"files/figures/perceptron.jpg\" width=\"300px\"/>\n",
    "    \n",
    "It dynamics is given as follows:\n",
    "\n",
    "$$\n",
    "y = \\sigma \\left( \\boldsymbol{w}^T \\boldsymbol{x} + b \\right) = \n",
    "\\begin{cases}\n",
    "+1 \\text{, if } \\boldsymbol{w}^T \\boldsymbol{x} + b \\geq 0 \\\\\n",
    "-1 \\text{, if } \\boldsymbol{w}^T \\boldsymbol{x} + b < 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\boldsymbol{x} = (x_1, \\dots, x_M)$ is the *inputs*,\n",
    "- $\\boldsymbol{w} = (w_1, \\dots, w_M)$ are the *(synaptic) weights* and $b$ is the *bias*,\n",
    "- $y$ is the *output*.\n",
    "\n",
    "By convention, we will use the following notations:\n",
    "- $\\boldsymbol{x} := (1, x_1, \\dots, x_M)$\n",
    "- $\\boldsymbol{w} := (w_0, w_1, \\dots, w_M)$, where $w_0 = b$.\n",
    "\n",
    "Accordingly, the dynamics of the perceptron is given by:\n",
    "\n",
    "$$\n",
    "y = \\sigma \\left( \\boldsymbol{w}^T \\boldsymbol{x} \\right).\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a4f3e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Consider the training set\n",
    "\n",
    "$$\n",
    "S = \\left\\{ \\left( \\boldsymbol{x_k}, y_k \\right) \\in \\mathbb{R}^M \\times \\{ -1, +1 \\} : k = 1, \\dots, K \\right\\}.\n",
    "$$\n",
    "\n",
    "\n",
    "The **training algorithm** of the perceptron consists in finding the weights and bias\n",
    "    \n",
    "$$\n",
    "\\boldsymbol{\\hat w} := (\\hat w_1, \\dots, \\hat w_M, \\hat b)\n",
    "$$\n",
    "\n",
    "such that the training set is classified correctly, i.e.,\n",
    "    \n",
    "$$\n",
    "\\sigma \\left( \\boldsymbol{\\hat w}^T \\boldsymbol{x_k} \\right) = y_k \\text{ for all } k = 1, \\dots, K.\n",
    "$$\n",
    "\n",
    "The **training algorithm** works as follows:\n",
    "\n",
    "Start with $\\boldsymbol{w} = (0, 0, \\dots, 0)$;<br>\n",
    "For $e = 1, \\dots, nb\\_epochs$:<br>\n",
    "&nbsp; For $k = 1, \\dots, K$:<br>\n",
    "&nbsp; &nbsp; If $(\\boldsymbol{x_k}, y_k)$ is misclassified, i.e., $\\sigma \\left( \\boldsymbol{\\hat w}^T \\boldsymbol{x_k} \\right) \\neq y_k$:<br>\n",
    "&nbsp; &nbsp; &nbsp; Then update the weights: $\\boldsymbol{w} := \\boldsymbol{w} + y_k \\boldsymbol{x_k}$.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9e323",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Remarks:**\n",
    "- The equation $\\boldsymbol{\\hat w}^T \\boldsymbol{x} = 0$ represents a *hyperplan* in the input space $\\mathbb{R}^M$.\n",
    "- The weights $\\boldsymbol{\\hat w}$ represents the *normal vector* or *parameters* of this hyperplan.\n",
    "- Therefore, the training algorithm of the perceptron consists in finding a hyperplan that separates the data correctly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c16d2",
   "metadata": {},
   "source": [
    "Generate $K = 100$ training points $(\\boldsymbol{x_k}, y_k),~ k = 1, \\dots, K$ in $\\mathbb{R}^2 \\times \\{ -1, +1 \\}$ that are *linearly separable*.\n",
    "\n",
    "- The \"positive\" (\"negative\") points $\\boldsymbol{x_k},~ k = 1, \\dots, K$ are stored in a tensor `x_pos` (`x_neg`) of dim $K \\times 2$.\n",
    "- The \"positive\" (\"negative\") labels $y_k,~ k = 1, \\dots, K$ are stored in a tensor `y_pos` (`y_neg`) of dim $K$.\n",
    "\n",
    "For instance, you can generate your points with `torch.normal(...)`, using different means and stds for two the different classes.\n",
    "\n",
    "Plot your training points using `matplolib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3321f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e748d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80fef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a3731cb",
   "metadata": {},
   "source": [
    "Create a function `plot_dataset(x_pos, y_pos, x_neg, y_neg, w)` which:\n",
    "- plots the \"positive\" points `x_pos` and the \"negative\" points `x_neg` in different colors; \n",
    "- plots the hyperplan $\\boldsymbol{w}^T \\boldsymbol{x} = 0$ parametrized by `w` (where `w = (w_1, w_2, b)`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0626c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b50f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7b29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ddb64eb",
   "metadata": {},
   "source": [
    "Merge yours training points `x_pos`, `y_pos` and `x_neg`, `y_neg` into a single **shuffled training set** `x`, `y`.\n",
    "\n",
    "To shuffle, use `torch.randperm(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759599c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11dfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361c68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42cb3850",
   "metadata": {},
   "source": [
    "Create a function `train_perceptron(x, y, nb_epochs)` that implements the training algorithm of the perceptron on the training set `x`, `y`.\n",
    "\n",
    "The parameter `nb_epochs` makes the algo stops after `nb_epochs` passes of the training set.\n",
    "\n",
    "The function should return the parameters `w = (w_1, w_2, b)` of the hyperplan obtained after training.\n",
    "\n",
    "Apply the function to your training set `x`, `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991b868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b6bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8275fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6af3746",
   "metadata": {},
   "source": [
    "Plot your training set as well as the best hyperplan returned by `train_perceptron` (use your function `plot_dataset`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1541744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577da9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42ed0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab415f92",
   "metadata": {},
   "source": [
    "Modify your function `train_perceptron(x, y, nb_epochs)` so that it returns the list of all hyperplans (paramters `w`) encountered during training.\n",
    "\n",
    "Retrain your perceptron on the train set.\n",
    "\n",
    "Plot some of the hyperplans (5 or 10 of them) encountered during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b8ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31f397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f920cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
