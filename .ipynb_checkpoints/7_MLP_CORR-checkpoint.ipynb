{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d77b0",
   "metadata": {},
   "source": [
    "# Multi Layer Percepron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4941630",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e5997",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8082",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "The **multi layer perceptron (MLP)** is feedforward neural network composed of successive layers (cf. Figure below).\n",
    "\n",
    "<img src=\"files/figures/MLP.jpg\" width=\"600px\"/>\n",
    " \n",
    "The dynamics of an MLP is given by the following equations (sample and batch versions):\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\textbf{sample $\\boldsymbol{x}$} & \\textbf{batch $\\boldsymbol{X_i}$} \\\\\n",
    "\\begin{cases}\n",
    "\\boldsymbol{a^{[0]}} ~=~ \\boldsymbol{x} & \\\\\n",
    "\\boldsymbol{z^{[l]}} ~=~ \\boldsymbol{W^{[l]}} \\boldsymbol{a^{[l-1]}} + \\boldsymbol{b^{[l]}}, & l = 1, \\dots, L \\\\\n",
    "\\boldsymbol{a^{[l]}} ~=~ \\boldsymbol{\\sigma} \\left( \\boldsymbol{z^{[l]}} \\right), & l = 1, \\dots, L\n",
    "\\end{cases}\n",
    "~&~\n",
    "\\begin{cases}\n",
    "\\boldsymbol{A^{[0]}} ~=~ \\boldsymbol{X_i}\t\\\\\n",
    "\\boldsymbol{Z^{[l]}} ~=~ \\boldsymbol{W^{[l]}} \\boldsymbol{A^{[l-1]}} \\oplus \\boldsymbol{b^{[l]}}, & l = 1, \\dots, L \\\\\n",
    "\\boldsymbol{A^{[l]}} ~=~ \\boldsymbol{\\sigma} \\big( \\boldsymbol{Z^{[l]}} \\big), & l = 1, \\dots, L\n",
    "\\end{cases}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab415f92",
   "metadata": {},
   "source": [
    "- Define a class `MLP()` which takes a list `[n1, n2, ..., nL]` as parameter and creates an MLP with $L$ layers of $n_i$ neurons each, for $i= 1, \\dots, L$.\n",
    "- Initializes the weights matrices $\\boldsymbol{W^{[l]}}$ and the bias vectors $\\boldsymbol{b^{[l]}}$ randomly from a normal distribution $\\mathcal{N}(0, 1)$ (`torch.normal()`).\n",
    "- The first layer is the input layer and thus has no biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3a10552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"constructor\"\"\"\n",
    "        \n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [torch.normal(0, 1, size=(n, 1)) \n",
    "                       for n in sizes[1:]] # no bias for 1st layer\n",
    "        self.weights = [torch.normal(0, 1, size=(n2, n1)) \n",
    "                        for n1, n2 in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"forward pass\"\"\"\n",
    "        \n",
    "        if X.shape[0] != self.sizes[0]:\n",
    "            raise ValueError(\"incorrect input dimension\")\n",
    "        \n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            X = torch.tanh(torch.mm(W, X) + b)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    def forward_penultimate(self, X):\n",
    "        \"\"\"\n",
    "        forward pass that stops at the penultimate layer\n",
    "        (cf. last point of the exercice)\n",
    "        \"\"\"\n",
    "        \n",
    "        if X.shape[0] != self.sizes[0]:\n",
    "            raise ValueError(\"incorrect input dimension\")\n",
    "        \n",
    "        for W, b in zip(self.weights[: -1], self.biases[: -1]):\n",
    "            X = torch.tanh(torch.mm(W, X) + b)\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed07c5",
   "metadata": {},
   "source": [
    "- Add a method `forward(X)` which takes a batch of vectors `X` as inputs (2D tensor), and computes the forward pass of the network on this batch.\n",
    "- For the activation function $\\sigma$, take the `tanh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7fa9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP([10, 30, 30, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "152dbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(10, 64) # batch of 64 inputs of size 10 each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "855b5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = net.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e64e40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edac4cd",
   "metadata": {},
   "source": [
    "## Application to the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293f4a4",
   "metadata": {},
   "source": [
    "The **MNIST dataset** consists of handwritten digits. The MNIST classification problem consists in predicting the correct digit represented on an image.\n",
    "\n",
    "<img src=\"files/figures/mnist.png\" width=\"600px\"/>\n",
    "\n",
    "- Load the train and test MNIST datasets using the following commands:\n",
    "```\n",
    "train = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "```\n",
    "Each sample consists of a tensor (the image encoded in black and white), and a label (the digit that it represents).\n",
    "- Examine the train and test sets.\n",
    "- Visualize some data samples (tensors) using `plt.imshow()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1950affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ec6f6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d238e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_set[47][0]\n",
    "target = train_set[47][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5129ce4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape # 3D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd653d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.view(28, 28) # reshape into 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "983cce60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe4f8f5d400>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d85e3f",
   "metadata": {},
   "source": [
    "Each sample is a $28 \\times 28$ 2D-tensor representing a handwritten digit. Note that the sample can be \"flattened\"  into a $28 \\cdot 28 = 784$ 1D-vector using the method `flatten()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1b062d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1d = sample.flatten()\n",
    "sample_1d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5b9e2",
   "metadata": {},
   "source": [
    "A **dataloader** creates batches of samples from a dataset so that they can be passed into a model.\n",
    "- Create a train and test dataloader using the following commands:\n",
    "```\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "```\n",
    "- Note that dataloaders are not subscriptable.\n",
    "- Try to catch one batch of the dataloader and examine it.\n",
    "- Write a function that reshapes a batch of size $64 \\times 1 \\times 28 \\times 28$ into a tensor of size $784 \\times 64$.<br>\n",
    "(use `torch.squeeze()`, `torch.reshape()`, `torch.flatten()`, `torch.transpose()`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1a49538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32ea03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06ab2820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0acbe218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_reshaped = torch.squeeze(b[0])\n",
    "b_reshaped = torch.flatten(b_reshaped, 1, 2)\n",
    "b_reshaped = b_reshaped.transpose(0, 1)\n",
    "b_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ea62b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_batch(b):\n",
    "    \"\"\"reshape batch of tensors\"\"\"\n",
    "    b = torch.squeeze(b)\n",
    "    b = torch.flatten(b, 1, 2).T\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31a13eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 64])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_reshaped = reshape_batch(b[0])\n",
    "b_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bbb26e",
   "metadata": {},
   "source": [
    "- Instantiate a 4-layer MLP with the following characteristics:\n",
    "    - Layer 1 (or input layer): size 784\n",
    "    - Layer 2: size 128\n",
    "    - Layer 3: size 128\n",
    "    - Layer 4 (or output layer): size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0d5719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP([784, 128, 128, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a679d",
   "metadata": {},
   "source": [
    "- Pass all train samples through your network batch by batch:<br>\n",
    "Create a function `process_data(dataloader, network)` that performs this.\n",
    "- Gather all the outputs into 1 tensor.\n",
    "- Take the argmax of the outputs to obtain the predictions.\n",
    "- Get the classification report associated to your predictions and real labels:<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "- What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e7df52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dataloader, network):\n",
    "    \"\"\"\n",
    "    Pass a dataloder into a network.\n",
    "    Return targets and predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for b in dataloader:\n",
    "\n",
    "        # samples and targets\n",
    "        samples = reshape_batch(b[0])\n",
    "        targets = b[1]\n",
    "        all_targets.extend(targets)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = network.forward(samples)\n",
    "        predictions = torch.argmax(outputs, dim=0)\n",
    "        all_predictions.extend(predictions)\n",
    "    \n",
    "    return all_targets, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5234f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets, all_predictions = process_data(train_loader, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7aace094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_targets), len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48f86e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(2), tensor(1), tensor(7), tensor(1), tensor(1)],\n",
       " [tensor(4), tensor(0), tensor(2), tensor(7), tensor(2)])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_targets[0:5], all_predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ec85321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.12      0.09      5923\n",
      "           1       0.06      0.07      0.06      6742\n",
      "           2       0.07      0.07      0.07      5958\n",
      "           3       0.00      0.00      0.00      6131\n",
      "           4       0.15      0.45      0.22      5842\n",
      "           5       0.06      0.09      0.07      5421\n",
      "           6       0.21      0.16      0.18      5918\n",
      "           7       0.03      0.01      0.02      6265\n",
      "           8       0.10      0.02      0.04      5851\n",
      "           9       0.08      0.03      0.04      5949\n",
      "\n",
      "    accuracy                           0.10     60000\n",
      "   macro avg       0.08      0.10      0.08     60000\n",
      "weighted avg       0.08      0.10      0.08     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train results\\n\")\n",
    "print(classification_report(all_targets, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "476da6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.12      0.10       980\n",
      "           1       0.05      0.06      0.06      1135\n",
      "           2       0.08      0.08      0.08      1032\n",
      "           3       0.02      0.00      0.00      1010\n",
      "           4       0.14      0.45      0.21       982\n",
      "           5       0.07      0.09      0.08       892\n",
      "           6       0.15      0.12      0.13       958\n",
      "           7       0.03      0.01      0.02      1028\n",
      "           8       0.15      0.03      0.06       974\n",
      "           9       0.09      0.04      0.05      1009\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.09      0.10      0.08     10000\n",
      "weighted avg       0.08      0.10      0.08     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_targets, all_predictions = process_data(test_loader, mlp)\n",
    "\n",
    "print(\"Test results\\n\")\n",
    "print(classification_report(all_targets, all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f4207",
   "metadata": {},
   "source": [
    "**Oviously, the network is untrained, and thus does not preforms better than chance (10%)!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58043b",
   "metadata": {},
   "source": [
    "## Train the MLP via Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c4c94",
   "metadata": {},
   "source": [
    "- Update the **weights of the last layer** only so that they correspond to the solution of a **Ridge regression**.<br>\n",
    "https://en.wikipedia.org/wiki/Ridge_regression<br>\n",
    "\n",
    "More precisely:\n",
    "- Pass the train set through the network and get the predictions of the penultimate layer<br>\n",
    "(add a method `forward_penultimate()` in the class `MLP`)\n",
    "- Compute the closed-form solution of the Ridge regression:\n",
    "\n",
    "$$\n",
    "{\\displaystyle {\\widehat {\\beta }}_{\\text{ridge}}=(X^{T}X+kI_{p})^{-1}X^{T}y}\n",
    "$$\n",
    "\n",
    "where\n",
    "- $X$ is the <span style=\"color:blue\">row-wise concatenation</span> of the penultimate outputs $\\boldsymbol{a_i}^{[L-1]}$, for $i = 1, \\dots, N$;\n",
    "- $I_{p}$ is the identity matrix of dim $p$;\n",
    "- $k > 0$ is a regularization parameter (e.g. $0.1$);\n",
    "- $y$ is the <span style=\"color:blue\">row-wise concatenation</span> of the 1-hot encoded targets $\\boldsymbol{y_i}$, for $i = 1, \\dots, N$ (`torch.nn.functional.one_hot()`).\n",
    "- **Set weights of the last layer $\\boldsymbol{W}^{[L]}$ as the solution of the Ridge regression.**\n",
    "- **Set the bias of the last layer $\\boldsymbol{b}^{[L]}$ to $\\boldsymbol{0}$.**\n",
    "- Recompute the predictions associated to the train and test sets.\n",
    "- Compute the classification reports.\n",
    "- What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3155a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get outputs of the penultimate layer and targets\n",
    "\n",
    "def process_penultimate_data(dataloader, network):\n",
    "    \"\"\"\n",
    "    Pass a dataloder into a network and stops at the punultimate layers.\n",
    "    Return targets and predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    all_targets = []\n",
    "    all_penultimate_outputs = [] # modif\n",
    "\n",
    "    for b in dataloader:\n",
    "\n",
    "        # samples and targets\n",
    "        samples = reshape_batch(b[0])\n",
    "        targets = b[1]\n",
    "        all_targets.extend(targets)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = network.forward_penultimate(samples) # modif\n",
    "        all_penultimate_outputs.append(outputs)        # modif: append output batches\n",
    "    \n",
    "    return all_targets, all_penultimate_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a85b9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_targets, all_penultimate_outputs = process_penultimate_data(train_loader, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d5fe10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 938)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_train_targets), len(all_penultimate_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5e84b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute solution of the Ridge regression\n",
    "\n",
    "def get_ridge_solution(X, y, k=0.1):\n",
    "    \"\"\"Computes the closed-form solution of the Ridge regression.\"\"\"\n",
    "    \n",
    "    # create tensor of all targets\n",
    "    targets = torch.tensor(y)\n",
    "    # one-hot encode the targets\n",
    "    targets = torch.nn.functional.one_hot(targets, num_classes=10)\n",
    "    targets = targets.float() # cast to float for later matrix multiplication\n",
    "    \n",
    "    # create tensor of all outputs\n",
    "    outputs = torch.cat(X, dim=1)\n",
    "    outputs = outputs.T # make outputs row-wise concatenation \n",
    "    \n",
    "    # compute ridge solution\n",
    "    X_tmp = torch.mm(outputs.T, outputs) + k*torch.eye(outputs.shape[1])\n",
    "    X_tmp = torch.mm(torch.pinverse(X_tmp), outputs.T)\n",
    "    beta = torch.mm(X_tmp, targets).T\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5cc1d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = get_ridge_solution(all_penultimate_outputs, all_train_targets, k=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5ee5a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 128])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b95cd6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the weights of the last layer as the solution of the Ridge regression\n",
    "\n",
    "mlp.weights[-1] = beta\n",
    "mlp.biases[-1] = torch.zeros(size=(10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90593c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80      5923\n",
      "           1       0.78      0.94      0.85      6742\n",
      "           2       0.70      0.67      0.68      5958\n",
      "           3       0.67      0.72      0.70      6131\n",
      "           4       0.69      0.57      0.63      5842\n",
      "           5       0.71      0.40      0.51      5421\n",
      "           6       0.70      0.85      0.77      5918\n",
      "           7       0.74      0.82      0.78      6265\n",
      "           8       0.67      0.51      0.58      5851\n",
      "           9       0.65      0.65      0.65      5949\n",
      "\n",
      "    accuracy                           0.71     60000\n",
      "   macro avg       0.70      0.70      0.69     60000\n",
      "weighted avg       0.71      0.71      0.70     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With this new MLP, compute the train and test predictions and the classification reports.\n",
    "\n",
    "all_targets, all_predictions = process_data(train_loader, mlp)\n",
    "print(\"Train results\\n\")\n",
    "print(classification_report(all_targets, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fee088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.81       980\n",
      "           1       0.80      0.95      0.87      1135\n",
      "           2       0.72      0.66      0.69      1032\n",
      "           3       0.70      0.75      0.73      1010\n",
      "           4       0.70      0.57      0.63       982\n",
      "           5       0.70      0.40      0.51       892\n",
      "           6       0.68      0.83      0.75       958\n",
      "           7       0.74      0.81      0.77      1028\n",
      "           8       0.66      0.51      0.58       974\n",
      "           9       0.66      0.69      0.67      1009\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_targets, all_predictions = process_data(test_loader, mlp)\n",
    "\n",
    "print(\"Test results\\n\")\n",
    "print(classification_report(all_targets, all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d1106",
   "metadata": {},
   "source": [
    "**The results have drastically improved!**\n",
    "- Note that $\\boldsymbol{W}^{[1]}, \\boldsymbol{W}^{[2]}$ are kept untrained (randomly initialized).\n",
    "- Only $\\boldsymbol{W}^{[3]}$ is trained via by a **Ridge regression**.\n",
    "- This suffices to drastically improve the results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
